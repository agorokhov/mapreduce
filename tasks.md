### Часть 1 (Hadoop Java API)
#### 1
Данные: статьи википедии (id -> text)
`/data/wiki/en_articles_part`, `/data/wiki/en_articles` 

Посчитать число вхождений слов (wordcount), начинающихся на ту же букву, что и ваше имя. Слова очистить от знаков пунктуации.
Результат отсортировать по убыванию числа вхождений.

Результат: слово, число

#### 2
Данные: статьи википедии (id -> text)
`/data/wiki/en_articles_part`, `/data/wiki/en_articles` 

Посчитать число вхождений слов (wordcount) длинной от 6 до 9 символов. 
Слова очистить от знаков пунктуации.
Результат отсортировать по убыванию числа вхождений.

Результат: слово, число

#### 3
Данные: статьи википедии (id -> text)
`/data/wiki/en_articles_part`, `/data/wiki/en_articles` 

Посчитать число вхождений имён собственных (wordcount). 
Слова очистить от знаков пунктуации.
Результат отсортировать по убыванию числа вхождений.
Способы получения имен собственных, на выбор:

1. слова, начинающиеся с прописной буквы
2. слова, всегда начинающиеся с прописной буквы (т.е. в тексте они ни разу не встретились со строчной буквой вначале)
3. несколько подряд идущих слов с прописной буквы
4. ваш вариант

Результат: слово, число

#### 4

Данные: статьи википедии (id -> text)
`/data/wiki/en_articles_part`, `/data/wiki/en_articles` 

Построить обратный поисковый индекс. Также посчитать число вхождений слова (term) в каждую статью (term frequency, tf). 
Слова очистить от знаков пунктуации.
 
Результат: term, article id, tf

#### 5
Данные: статьи википедии (id -> text)
`/data/wiki/en_articles_part`, `/data/wiki/en_articles` 

Исследовать возможность построения обратного поискового индекса в виде цепочек: слово (term) -> список article id. 
Для этого посчитать число статей для каждого слова (т.е. слово считается только один раз на статью). 
Слова очистить от знаков пунктуации. Результат отсортировать по количеству.
 
Результат: term, number of articles

#### 6
Данные: текст «Горе от ума» `/data/griboedov`: персонаж -> строка реплики 

Посчитать число слов для каждого персонажа, число реплик и число слов на реплику. 
Одна реплика персонажа - это несколько подряд идущих фраз (строк) этого персонажа.
Слова очистить от знаков пунктуации. 

Результат: персонаж, число слов, число реплик, число слов на реплику


#### 7
Данные: текст «Горе от ума» /data/griboedov персонаж -> строка реплики 

Посчитать богатство языка (число уникальных слов) каждого персонажа и число реплик. Одна реплика персонажа - это несколько подряд идущих фраз (строк) этого персонажа. Слова очистить от знаков пунктуации. 

Результат: персонаж, число уник. cлов, число реплик 

#### 8
Данные: случайные точки в квадрате [-1, 1]
`/data/random_points` или число точек и число мапперов, переданные в параметрах задачи.

Оценить значение числа π методом Монте Карло. Использовать счетчики для подсчета числа точек в каждой коорд. четверти.
Можно не использовать заданные данные, а генерировать случайные точки прямо на mapper’е, (см. пример [PiEstimator.java](http://www.docjar.com/html/api/org/apache/hadoop/examples/PiEstimator.java.html)) 

**Обязатальна реализация на новом Hadoop Java API.**

Результат: файл с оценкой и вывод оценки в консоль

#### 9
Данные: статьи википедии (id -> text)
`/data/wiki/en_articles_part`, `/data/wiki/en_articles` 

Посчитать число вхождений пар слов в тексте.
Слова очистить от знаков пунктуации. 
Результат отсортировать по числу вхождений.

Результат: пара слов, число

#### 10
Данные: некие идентификаторы, по одному на строку
`/data/ids_part`, `/data/ids` 

Идентификаторы перемешать в случайном порядке. Далее в одной строке записать через запятую случайное число идентификаторв - от 1 до 5.

Результат: id1,id2,...

Способ перемешивания записей: дописать к каждой случайное число, отсортировать по нему весь список, потом число отбросить.


### Часть 2
Можно использовать Java API или streaming. Для первых 2х задач, в случае реализации на Java, обязательно новое Java API. Для первой задачи можно воспользоваться одним из способов, описанных в статье [http://www.norstad.org/matrix-multiply/](http://www.norstad.org/matrix-multiply/).

#### Данные
Задачи двух типов: на перемножение больших матриц и на статистические расчеты. Матрицы записаны в comma-separated формате: индекс строки, столбца и значение. Находятся в HDFS в директориях /data/matrix/A,  /data/matrix/B,  /data/matrix/С.

Для статистических расчетов есть данные о посещениях пользователями страниц в Сети с отметкой в времени посещения и времени, которое пользователь провел на странице. Период сбора данных - 2 недели. Формат файла данных - текст в tab-separated формате с полями user_id, timestamp, url, 'diff_time':time_on_page. 

Например:   
`7884862957065236246     1412508741      http://lenta.ru/articles/2014/10/05/teacher/    diff_time:63`   

Тут 7884862957065236246 - обезличенный идентификатор пользователя, 1412508741 - timestamp, как принято в Unix в секундах с 01.01.1970, далее адрес страницы и время на странице в секундах (diff\_time: - в данном случае ненужный префикс). Данные в HDFS в директории `/data/user_events` и семпл для отладки в `/data/user_events_part`.

#### 1
Посчитать произведение матриц A (5000x20000) и B (20000х2000). Для избежания переполнения все операции (умножение и сложение) производить по модулю 97. В процессе вычислений ни одна матрица в память полностью не зачитывается (reduce-side join). Обязательно новое Hadoop Java API или streaming.

#### 2 
Посчитать произведение матриц A (5000x20000) и C (20000х50). Для избежания переполнения все операции (умножение и сложение) производить по модулю 97. Матрица С передаётся через distributed cache, может целиком или частично подниматься в память для эффективного join (на mapper или reducer). Обязательно новое Hadoop Java API или streaming.

#### 3
По данным посещений пользователями страниц посчитать медиану и 3й квартиль (см. https://ru.wikipedia.org/wiki/%CA%E2%E0%ED%F2%E8%EB%FC) времен, проведенных на страницах на каждый домен. Если результат в виде одного файла: домен, медиана и квартиль - то отсортирован по медиане. Если в виде 2х отдельных файлов, то каждый отсортирован по своему статистическому показателю. Т.е. запись вида   
youtube.com  10  20    
означает, что на страницах с домена youtube.com половина визитов были не длиннее 10 секунд и 75% визитов - не длиннее 20 секунд.

#### 4
Рейтинг посещений доменов в будние дни с 07:00 до 18:59 ("рабочее" время) и с 19:00 до 06:59 ("нерабочее"). При этом выходные исключаются полностью, т.е. вечер пятницы длится до 23:59. Результат в виде одного файла с тремя полями: домен, посещения в рабочее, посещения в нерабочее время. Сортировка по второму полю. Пример:   
lenta.ru   500 300  
означает, что сайт lenta.ru посещали 500 раз в рабочее время и 300 раз - в нерабочее.  
*Бонус:* перевести посещения в позиции в рейтинге, т.е. чтобы   
lenta.ru   5 10   
означало, что lenta.ru в рабочее время на 5м месте по посещениям, а в остальное время - на 10м.

#### 5
То же, что задача 4, только будни против выходных.

#### 6
Для каждого url посчитать отношение число визитов на url к количеству уникальных пользователей на данном url (т.е. visits per user). Результат в виде: url, visits per user; сортировка по второму полю.  
Смысл показателя число визитов на пользователя - возвращаемость пользователя на страницу. Для главных страниц порталов, новостных ресурсов, vk.com/feed этот показатель должен быть высоким. Для аналитических, художественных, научно-популярных, новостных статей - близким к единице: один раз прочитал и достаточно.    
Для отсечения статистически незначимых результатов (где один пользователь сделал 10 заходов и всё), рекомендуется использовать сглаживание: в числитель и знаменатель добавлять слагаемое, т.е. 
visits per user = (visits + A) / (users + B),   
где A и B берутся эмпирически. Например, при A = 100 и B = 10 для страниц, у которых посещаемость порядка 100 визитов и 10 пользователей, результат занижаем. 

#### 7
Оценить среднее время жизни страниц домена в днях. Отсортировать по времени жизни, результат:
echo.msk.ru  5
означает, что на сайте "Эхо Москвы" статьи в среднем посещаются 5 дней.
Смысл показателя: на новостных сайтах страницы меняются быстро, на материалы глянцевых, автомобильных, и научно-популярных журналов пользователи приходят в течение нескольких недель. Можно проверить гипотезу о том, что среднее время жизни статей на таких сайтах будем разным.
